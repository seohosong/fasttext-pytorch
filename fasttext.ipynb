{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(',', '').replace('.','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(set(clean_text(raw_text).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(words, window=3):\n",
    "    start_token = '<'\n",
    "    end_token = '>'\n",
    "    \n",
    "    ngram_list = []\n",
    "    all_tokens = []\n",
    "    for word in words:\n",
    "        word = start_token + word + end_token\n",
    "        ngrams = []\n",
    "        for ix in range(0, len(word) - window//2 - 1):\n",
    "            ngram = word[ix:ix+window]\n",
    "            ngrams.append(ngram)\n",
    "            all_tokens.append(ngram)\n",
    "        ngram_list.append(ngrams)\n",
    "    \n",
    "    return ngram_list, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_list, all_tokens = build_vocab(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<sp', 'spe', 'pel', 'ell', 'lls', 'ls>'], ['<As', 'As>'], ['<Th', 'The', 'he>'], ['<co', 'com', 'omp', 'mpu', 'put', 'ute', 'ter', 'ers', 'rs>'], ['<pr', 'pro', 'rog', 'ogr', 'gra', 'ram', 'am>'], ['<th', 'the', 'hey', 'ey>'], ['<is', 'is>'], ['<In', 'In>'], ['<ru', 'rul', 'ule', 'les', 'es>'], ['<th', 'the', 'he>'], ['<id', 'ide', 'dea', 'ea>'], ['<sp', 'spi', 'pir', 'iri', 'rit', 'its', 'ts>'], ['<ab', 'abo', 'bou', 'out', 'ut>'], ['<We', 'We>'], ['<ma', 'man', 'ani', 'nip', 'ipu', 'pul', 'ula', 'lat', 'ate', 'te>'], ['<ab', 'abs', 'bst', 'str', 'tra', 'rac', 'act', 'ct>'], ['<ev', 'evo', 'vol', 'olv', 'lve', 've>'], ['<by', 'by>'], ['<to', 'to>'], ['<ef', 'eff', 'ffe', 'fec', 'ect', 'ct>'], ['<co', 'com', 'omp', 'mpu', 'put', 'ute', 'ter', 'er>'], ['<a>'], ['<in', 'inh', 'nha', 'hab', 'abi', 'bit', 'it>'], ['<th', 'thi', 'hin', 'ing', 'ngs', 'gs>'], ['<pr', 'pro', 'roc', 'oce', 'ces', 'ess', 'ss>'], ['<ca', 'cal', 'all', 'lle', 'led', 'ed>'], ['<di', 'dir', 'ire', 'rec', 'ect', 'cte', 'ted', 'ed>'], ['<ou', 'our', 'ur>'], ['<pr', 'pro', 'rog', 'ogr', 'gra', 'ram', 'ams', 'ms>'], ['<be', 'bei', 'ein', 'ing', 'ngs', 'gs>'], ['<th', 'tha', 'hat', 'at>'], ['<pa', 'pat', 'att', 'tte', 'ter', 'ern', 'rn>'], ['<cr', 'cre', 'rea', 'eat', 'ate', 'te>'], ['<of', 'of>'], ['<pr', 'pro', 'roc', 'oce', 'ces', 'ess', 'sse', 'ses', 'es>'], ['<Co', 'Com', 'omp', 'mpu', 'put', 'uta', 'tat', 'ati', 'tio', 'ion', 'ona', 'nal', 'al>'], ['<wi', 'wit', 'ith', 'th>'], ['<da', 'dat', 'ata', 'ta>'], ['<ev', 'evo', 'vol', 'olu', 'lut', 'uti', 'tio', 'ion', 'on>'], ['<we', 'we>'], ['<Pe', 'Peo', 'eop', 'opl', 'ple', 'le>'], ['<st', 'stu', 'tud', 'udy', 'dy>'], ['<ar', 'are', 're>'], ['<ot', 'oth', 'the', 'her', 'er>'], ['<co', 'com', 'omp', 'mpu', 'put', 'uta', 'tat', 'ati', 'tio', 'ion', 'ona', 'nal', 'al>'], ['<di', 'dir', 'ire', 'rec', 'ect', 'ct>'], ['<co', 'con', 'onj', 'nju', 'jur', 'ure', 're>']]\n"
     ]
    }
   ],
   "source": [
    "print(ngram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sp', 'spe', 'pel', 'ell', 'lls', 'ls>', '<As', 'As>', '<Th', 'The', 'he>', '<co', 'com', 'omp', 'mpu', 'put', 'ute', 'ter', 'ers', 'rs>', '<pr', 'pro', 'rog', 'ogr', 'gra', 'ram', 'am>', '<th', 'the', 'hey', 'ey>', '<is', 'is>', '<In', 'In>', '<ru', 'rul', 'ule', 'les', 'es>', '<th', 'the', 'he>', '<id', 'ide', 'dea', 'ea>', '<sp', 'spi', 'pir', 'iri', 'rit', 'its', 'ts>', '<ab', 'abo', 'bou', 'out', 'ut>', '<We', 'We>', '<ma', 'man', 'ani', 'nip', 'ipu', 'pul', 'ula', 'lat', 'ate', 'te>', '<ab', 'abs', 'bst', 'str', 'tra', 'rac', 'act', 'ct>', '<ev', 'evo', 'vol', 'olv', 'lve', 've>', '<by', 'by>', '<to', 'to>', '<ef', 'eff', 'ffe', 'fec', 'ect', 'ct>', '<co', 'com', 'omp', 'mpu', 'put', 'ute', 'ter', 'er>', '<a>', '<in', 'inh', 'nha', 'hab', 'abi', 'bit', 'it>', '<th', 'thi', 'hin', 'ing', 'ngs', 'gs>', '<pr', 'pro', 'roc', 'oce', 'ces', 'ess', 'ss>', '<ca', 'cal', 'all', 'lle', 'led', 'ed>', '<di', 'dir', 'ire', 'rec', 'ect', 'cte', 'ted', 'ed>', '<ou', 'our', 'ur>', '<pr', 'pro', 'rog', 'ogr', 'gra', 'ram', 'ams', 'ms>', '<be', 'bei', 'ein', 'ing', 'ngs', 'gs>', '<th', 'tha', 'hat', 'at>', '<pa', 'pat', 'att', 'tte', 'ter', 'ern', 'rn>', '<cr', 'cre', 'rea', 'eat', 'ate', 'te>', '<of', 'of>', '<pr', 'pro', 'roc', 'oce', 'ces', 'ess', 'sse', 'ses', 'es>', '<Co', 'Com', 'omp', 'mpu', 'put', 'uta', 'tat', 'ati', 'tio', 'ion', 'ona', 'nal', 'al>', '<wi', 'wit', 'ith', 'th>', '<da', 'dat', 'ata', 'ta>', '<ev', 'evo', 'vol', 'olu', 'lut', 'uti', 'tio', 'ion', 'on>', '<we', 'we>', '<Pe', 'Peo', 'eop', 'opl', 'ple', 'le>', '<st', 'stu', 'tud', 'udy', 'dy>', '<ar', 'are', 're>', '<ot', 'oth', 'the', 'her', 'er>', '<co', 'com', 'omp', 'mpu', 'put', 'uta', 'tat', 'ati', 'tio', 'ion', 'ona', 'nal', 'al>', '<di', 'dir', 'ire', 'rec', 'ect', 'ct>', '<co', 'con', 'onj', 'nju', 'jur', 'ure', 're>']\n"
     ]
    }
   ],
   "source": [
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict()\n",
    "word2id = dict()\n",
    "for i, word in enumerate(list(set(all_tokens))):\n",
    "    id2word[i] = word\n",
    "    word2id[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram(sentence, window_size=2, neg_samples=5, raw_sentence=False):\n",
    "    pairs = []\n",
    "    if raw_sentence:\n",
    "        sentence = sentence.lower().split()\n",
    "    \n",
    "    for i, word in enumerate(sentence):\n",
    "        cnt = 0\n",
    "        for j in range(-window_size, window_size+1):\n",
    "            if j != 0 and (i+j) >= 0 and (i+j) < len(sentence):\n",
    "                pairs.append((sentence[i], sentence[i+j], 1))\n",
    "                cnt += 1\n",
    "                \n",
    "        #NAIVE negative sampling\n",
    "        for _ in range(neg_samples):\n",
    "            ran_num = random.randint(0, len(word2id)-1)\n",
    "            while ran_num == word2id[word]:\n",
    "                ran_num = random.randint(0, len(word2id)-1)\n",
    "            neg_sample = id2word[ran_num]\n",
    "            pairs.append((sentence[i], neg_sample, 0))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = skipgram(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_to_input(pairs, id2word, word2id):\n",
    "    center_ix = []\n",
    "    context_ix = []\n",
    "    targets = []\n",
    "    for pair in pairs:\n",
    "        center_ix.append(word2id[pair[0]])\n",
    "        context_ix.append(word2id[pair[1]])\n",
    "        targets.append(pair[2])\n",
    "    \n",
    "    return center_ix, context_ix, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_ix, context_ix, targets = pair_to_input(pairs, id2word, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.center_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.context_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "    def forward(self, u_ix, v_ix):\n",
    "        \n",
    "        u = self.context_emb(u_ix).view(1,-1)\n",
    "        v = self.center_emb(v_ix).view(1,-1)\n",
    "        score = torch.mm(u, v.transpose(1,0))\n",
    "        \n",
    "        return torch.sigmoid(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (center_emb): Embedding(191, 100)\n",
       "  (context_emb): Embedding(191, 100)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Skipgram(len(word2id), 100)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    optimizer = optim.SGD(lr=1e-3, params=model.parameters())\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        total_loss = 0.0\n",
    "        for i in range(len(pairs)):\n",
    "            center = torch.tensor(center_ix[i]).to(device).long()\n",
    "            context = torch.tensor(context_ix[i]).to(device).long()\n",
    "            target = torch.tensor(targets[i]).view(1,-1).to(device).float()\n",
    "            \n",
    "            out = model.forward(context, center)\n",
    "            loss = F.binary_cross_entropy(out, target)\n",
    "            total_loss += loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #if (i+1) % 300 == 0:\n",
    "            #    print('Epoch %d  %d steps, loss : %0.4f' %(epoch+1, i+1, loss))\n",
    "        print('Epoch %d | loss : %0.4f' %(epoch+1, total_loss / i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | loss : 1.6873\n",
      "Epoch 2 | loss : 1.6495\n",
      "Epoch 3 | loss : 1.6125\n",
      "Epoch 4 | loss : 1.5770\n",
      "Epoch 5 | loss : 1.5426\n",
      "Epoch 6 | loss : 1.5093\n",
      "Epoch 7 | loss : 1.4772\n",
      "Epoch 8 | loss : 1.4463\n",
      "Epoch 9 | loss : 1.4165\n",
      "Epoch 10 | loss : 1.3878\n",
      "Epoch 11 | loss : 1.3501\n",
      "Epoch 12 | loss : 1.3233\n",
      "Epoch 13 | loss : 1.2975\n",
      "Epoch 14 | loss : 1.2726\n",
      "Epoch 15 | loss : 1.2487\n",
      "Epoch 16 | loss : 1.2252\n",
      "Epoch 17 | loss : 1.2026\n",
      "Epoch 18 | loss : 1.1808\n",
      "Epoch 19 | loss : 1.1599\n",
      "Epoch 20 | loss : 1.1396\n",
      "Epoch 21 | loss : 1.1201\n",
      "Epoch 22 | loss : 1.1014\n",
      "Epoch 23 | loss : 1.0833\n",
      "Epoch 24 | loss : 1.0659\n",
      "Epoch 25 | loss : 1.0491\n",
      "Epoch 26 | loss : 1.0331\n",
      "Epoch 27 | loss : 1.0177\n",
      "Epoch 28 | loss : 1.0029\n",
      "Epoch 29 | loss : 0.9887\n",
      "Epoch 30 | loss : 0.9751\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
